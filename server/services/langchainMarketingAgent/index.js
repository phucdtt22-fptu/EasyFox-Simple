const { ChatOpenAI } = require("@langchain/openai");
const { ChatPromptTemplate } = require("@langchain/core/prompts");
const { createToolCallingAgent, AgentExecutor } = require("langchain/agents");
const { BufferMemory, ChatMessageHistory } = require("langchain/memory");
const systemPrompt = require("./systemPrompt");
const createTools = require("./tools");
const agentUtils = require("./agentUtils");

class LangChainMarketingAgent {
  constructor(supabaseClient) {
    this.supabase = supabaseClient;
    this.model = new ChatOpenAI({
      modelName: process.env.OPENAI_CHAT_MODEL || "gpt-4o-mini",
      temperature: 0.3,
      openAIApiKey: process.env.OPENAI_API_KEY,
      maxTokens: 2000,
    });
    this.systemPrompt = systemPrompt;
  }

  async getAgentExecutor(tools, chatHistory = []) {
    console.log('ðŸ”§ Creating agent with tools:', tools.map(t => t.name));
    console.log('ðŸ“œ System prompt length:', this.systemPrompt.length);
    console.log('ðŸ’¬ Chat history length:', chatHistory.length);
    
    // Create ChatMessageHistory properly
    const messageHistory = new ChatMessageHistory();
    
    // Add chat history messages if any
    if (chatHistory && chatHistory.length > 0) {
      for (const msg of chatHistory) {
        if (msg.role === 'user') {
          await messageHistory.addUserMessage(msg.content);
        } else if (msg.role === 'assistant') {
          await messageHistory.addAIMessage(msg.content);
        }
      }
    }

    // Use BufferMemory for chat history
    const memory = new BufferMemory({
      returnMessages: true,
      memoryKey: 'chat_history',
      inputKey: 'input',
      outputKey: 'output',
      chatHistory: messageHistory
    });

    // Create prompt template
    const prompt = ChatPromptTemplate.fromMessages([
      ["system", this.systemPrompt],
      ["placeholder", "{chat_history}"],
      ["human", "{input}"],
      ["placeholder", "{agent_scratchpad}"]
    ]);
    
    console.log('ðŸŽ¯ Created prompt template');
    
    // Bind tools to model first
    const modelWithTools = this.model.bindTools(tools);
    
    // Create agent using createToolCallingAgent
    const agent = await createToolCallingAgent({
      llm: modelWithTools,
      tools,
      prompt,
    });
    
    // Create executor with standard settings
    const executor = new AgentExecutor({
      agent,
      tools,
      memory,
      verbose: true,
      maxIterations: 3,
      returnIntermediateSteps: true,
    });
    
    console.log('âœ… Agent executor created successfully');
    return executor;
  }

  async processMessage(userId, message, onboardingNotes = null, chatHistory = [], onboardingData = null) {
    try {
      const tools = createTools(this.supabase, userId, agentUtils);

      // Special handling for onboarding data submission
      if (onboardingData) {
        const businessParagraph = await agentUtils.createBusinessParagraphFromData.call(this, onboardingData);
        const addOnboardingTool = tools.find(t => t.name === 'Add_Onboarding_Data');
        if (addOnboardingTool) {
          const result = await addOnboardingTool.func({ paragraph: businessParagraph });
          return {
            success: true,
            response: result
          };
        } else {
          throw new Error('Add_Onboarding_Data tool not found');
        }
      }

      // Use standard Tools Agent execution
      const agentExecutor = await this.getAgentExecutor(tools, chatHistory);

      // Create input for agent
      const input = onboardingNotes 
        ? `[THÃ”NG TIN DOANH NGHIá»†P]\n${onboardingNotes}\n\n[TIN NHáº®N NGÆ¯á»œI DÃ™NG]\n${message}`
        : message;

      console.log('ðŸ¤– Invoking agent with input:', input.substring(0, 100) + '...');

      const result = await agentExecutor.invoke({
        input: input
      });

      // Náº¿u cÃ³ tool call, tráº£ vá» quy trÃ¬nh agent dáº¡ng text Ä‘Æ¡n giáº£n
      if (result.intermediateSteps && result.intermediateSteps.length > 0) {
        let stepsText = 'ðŸ”§ QUY TRÃŒNH AGENT Sá»¬ Dá»¤NG TOOL:\n\n';
        
        for (let i = 0; i < result.intermediateSteps.length; i++) {
          const step = result.intermediateSteps[i];
          const action = step.action;
          const observation = step.observation;
          
          stepsText += `ðŸ“‹ BÆ°á»›c ${i + 1}: Agent gá»i tool "${action.tool}"\n`;
          stepsText += `ðŸ“¥ Input: ${JSON.stringify(action.toolInput, null, 2)}\n`;
          stepsText += `ðŸ“¤ Káº¿t quáº£: ${typeof observation === 'string' ? observation : JSON.stringify(observation, null, 2)}\n`;
          stepsText += `\n${'â”€'.repeat(50)}\n\n`;
        }
        
        // ThÃªm output cuá»‘i cÃ¹ng náº¿u cÃ³
        if (result.output) {
          stepsText += `âœ… Káº¾T LUáº¬N CUá»I CÃ™NG:\n${result.output}`;
        }
        
        return {
          success: true,
          response: stepsText
        };
      }
      // Náº¿u khÃ´ng cÃ³ tool call, tráº£ vá» text nhÆ° cÅ©
      return {
        success: true,
        response: result.output
      };
    } catch (error) {
      console.error('LangChain Marketing Agent error:', error);
      return {
        success: false,
        error: 'Xin lá»—i, tÃ´i gáº·p chÃºt váº¥n Ä‘á» ká»¹ thuáº­t. HÃ£y thá»­ láº¡i sau giÃ¢y lÃ¡t nhÃ©!',
        details: error.message
      };
    }
  }
}

module.exports = LangChainMarketingAgent;
